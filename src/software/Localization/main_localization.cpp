
#include <openMVG/image/image_io.hpp>
#include <nonFree/sift/SIFT_describer.hpp>
#include <openMVG/sfm/sfm_data_io.hpp>
#include <openMVG/sfm/sfm_data_io_ply.hpp>
#include <openMVG/sfm/pipelines/sfm_robust_model_estimation.hpp>
#include <openMVG/cameras/Camera_Pinhole.hpp>
#include <openMVG/localization/localization.hpp>
#include <openMVG/matching/regions_matcher.hpp>
#include <openMVG/matching_image_collection/Matcher.hpp>
#include <openMVG/matching/matcher_kdtree_flann.hpp>
#include <openMVG/matching_image_collection/F_ACRobust.hpp>
#include <openMVG/voctree/vocabulary_tree.hpp>
#include <openMVG/voctree/database.hpp>

//#include <opencv2/core/core.hpp>

#include <boost/filesystem/operations.hpp>
#include <boost/filesystem/path.hpp>
#include <boost/progress.hpp>
#include <boost/program_options.hpp> 

#include <iostream>
#include <string>

#define POPART_COUT(x) std::cout << x << std::endl
#define POPART_CERR(x) std::cerr << x << std::endl


namespace bfs = boost::filesystem;
namespace po = boost::program_options;

using namespace openMVG;

static const int DIMENSION = 128;


int main(int argc, char** argv)
{
  int numResults = 4; //< number of best matching images to retrieve from the database
  int numCommonViews = 3; //< number minimum common images in which a point must be seen to be used in cluster tracking
  std::string calibFile; //< the calibration file
  std::string sfmFilePath; ///< the OpenMVG .json data file
  std::string descriptorsFolder; ///< the OpenMVG .json data file
  std::string vocTreeFilepath; ///< the vocabulary tree file
  std::string weightsFilepath; ///< the vocabulary tree weights file
  std::string mediaFilepath; ///< the media file to localize
  std::string exportFilepath = "trackedcameras.json"; //!< the export file

  po::options_description desc(
                               "This program takes as input a media (image, image sequence, video) and a database (voctree, 3D structure data) \n"
                               "and returns for each frame a pose estimation for the camera.");
  desc.add_options()
          ("help,h", "Print this message")
          ("results,r", po::value<int>(&numResults)->default_value(numResults), "Number of images to retrieve in database")
          ("commonviews,", po::value<int>(&numCommonViews)->default_value(numCommonViews), "Number of minimum images in which a point must be seen to be used in cluster tracking")
          ("calibration,c", po::value<std::string>(&calibFile)/*->required( )*/, "Calibration file")
          ("voctree,t", po::value<std::string>(&vocTreeFilepath)->required(), "Filename for the vocabulary tree")
          ("weights,w", po::value<std::string>(&weightsFilepath), "Filename for the vocabulary tree weights")
          ("sfmdata,d", po::value<std::string>(&sfmFilePath)->required(), "The sfm_data.json kind of file generated by OpenMVG [it could be also a bundle.out to use an older version of OpenMVG]")
          ("siftPath,s", po::value<std::string>(&descriptorsFolder), "Folder containing the .desc. If not provided, it will be assumed to be parent(sfmdata)/matches [for the older version of openMVG it is the list.txt]")
          ("mediafile,m", po::value<std::string>(&mediaFilepath)->required(), "The folder path or the filename for the media to track")
          ("export,e", po::value<std::string>(&exportFilepath)->default_value(exportFilepath), "Filename for the SfM_Data export file (where camera poses will be stored). Default : trackedcameras.json If Alambic is enable it will also export an .abc file of the scene with the same name");

  po::variables_map vm;

  try
  {
    po::store(po::parse_command_line(argc, argv, desc), vm);

    if(vm.count("help") || (argc == 1))
    {
      POPART_COUT(desc);
      return EXIT_SUCCESS;
    }

    po::notify(vm);
  }
  catch(boost::program_options::required_option& e)
  {
    POPART_CERR("ERROR: " << e.what() << std::endl);
    POPART_COUT("Usage:\n\n" << desc);
    return EXIT_FAILURE;
  }
  catch(boost::program_options::error& e)
  {
    POPART_CERR("ERROR: " << e.what() << std::endl);
    POPART_COUT("Usage:\n\n" << desc);
    return EXIT_FAILURE;
  }

  const bool withWeights = vm.count("weights");

  {
    POPART_COUT("Program called with the following values:");
    POPART_COUT("\tvoctree: " << vocTreeFilepath);
    POPART_COUT("\tcalibration: " << calibFile);
    POPART_COUT("\tsfmdata: " << sfmFilePath);
    POPART_COUT("\tmediafile: " << mediaFilepath);
    POPART_COUT("\tsiftPath: " << descriptorsFolder);
    POPART_COUT("\tresults: " << numResults);
    POPART_COUT("\tcommon views: " << numCommonViews);
  }

  // check the input, if a json is provided we are using the new version of openMVG
  // otherwise switch to the old version with the list.txt and the bundle.out
  bool newVersion = bfs::path(sfmFilePath).extension().string() == ".json";

  // Load the JSON if we are using the new version of openMVG
  sfm::SfM_Data sfmData;
  if(newVersion)
  {
    POPART_COUT("Using OpenMVG data version > 0.8");
    if(sfm::Load(sfmData, sfmFilePath, sfm::ESfM_Data::ALL))
    {
      POPART_COUT("SfM data loaded from " << sfmFilePath << " containing: ");
      POPART_COUT("\tnumber of views      : " << sfmData.GetViews().size());
      POPART_COUT("\tnumber of poses      : " << sfmData.GetPoses().size());
      POPART_COUT("\tnumber of points     : " << sfmData.GetLandmarks().size());
      POPART_COUT("\tnumber of intrinsics : " << sfmData.GetIntrinsics().size());
    }
    else
    {
      POPART_CERR("Could not load the sfm_data file " << sfmFilePath << "!");
      return EXIT_FAILURE;
    }

    // Manage the descriptor folder, if not provided, use the parent directory of 
    // the sfmdata as base and add ./matches (usually it's where it is in the OpenMVG pipeline)
    if(!vm.count("siftPath"))
    {
      // Create a clean path to matches folder
      bfs::path matchespath(bfs::system_complete(bfs::path(sfmFilePath)));
      matchespath = matchespath.parent_path().parent_path();
      matchespath /= "matches";
      descriptorsFolder = matchespath.string();
    }
    POPART_COUT("The descriptors will be loaded from: " << descriptorsFolder);
  }
  else
  {
    POPART_COUT("Using OpenMVG data version < 0.8");
    if(!vm.count("siftPath"))
    {
      // in this case siftPath is mandatory!...
      POPART_CERR("In order to use the older version of OpenMVG you need to pass --siftPath pointing to the lists.txt file");
      return EXIT_FAILURE;
    }
  }

  // @todo: Load the calibration file

  // Views and Poses handles
  sfm::SfM_Data trackedcameras;
  // Store the camera calibration as a solo intrinsic (for each view, id_intrinsic = 0)
  trackedcameras.intrinsics[0] = std::make_shared<cameras::Pinhole_Intrinsic>(); // 0, 0, cameraCalib.getFocalLength( ), cameraCalib.getU0( ), cameraCalib.getV0( ) );
  trackedcameras.structure = sfmData.GetLandmarks();

  localization::VoctreeLocalizer localization;
  localization.loadReconstructionDescriptors(sfmData, descriptorsFolder);

  // Load vocabulary tree
  printf("Loading vocabulary tree\n");
  voctree::VocabularyTree<localization::DescriptorFloat> voctree(vocTreeFilepath);
  cout << "tree loaded with" << endl << "\t" << voctree.levels() << " levels" << endl << "\t" << voctree.splits() << " branching factor" << endl;

  POPART_COUT("Creating the database...");
  // Add each object (document) to the database
  openMVG::voctree::Database db(voctree.words());
  if(withWeights)
  {
    POPART_COUT("Loading weights...");
    db.loadWeights(weightsFilepath);
  }
  else
  {
    POPART_COUT("No weights specified, skipping...");
  }

  POPART_COUT("Populate the database using the loaded ReconstructedRegions");
  // Populate the database using the loaded ReconstructedRegions
  std::map<voctree::DocId, IndexT> mapDocIdToView;
  for(const auto regionsValue : localization._regions_per_view)
  {
    const IndexT viewId = regionsValue.first;
    const localization::Reconstructed_RegionsT& regions = regionsValue.second;
    std::vector<voctree::Word> words = voctree.quantize(regions._regions.Descriptors());
    voctree::DocId docId = db.insert(words);
    mapDocIdToView[docId] = viewId;
  }

  POPART_COUT("Load the query image");
  // load the query image
  image::Image<unsigned char> imageGray;
  if(!image::ReadImage(mediaFilepath.c_str(), &imageGray))
    throw std::runtime_error("Unable to read the media file.");
  POPART_COUT("Image size: " << imageGray.Width() << "x" << imageGray.Height());

  // Extract features from the query image
  features::SIFT_Image_describer describer;

  POPART_COUT("Extract SIFT from query image");
  std::unique_ptr<features::Regions> tmpQueryRegions(new features::SIFT_Regions());
  POPART_COUT("Describe");
  describer.Describe(imageGray, tmpQueryRegions, NULL);
  POPART_COUT("Extract SIFT done");
  features::SIFT_Regions queryRegions = *dynamic_cast<features::SIFT_Regions*> (tmpQueryRegions.get());
  POPART_COUT("Extract SIFT done!!");

  POPART_COUT("Request closest images from voctree");
  // Request closest images from voctree
  std::vector<voctree::Word> requestImageWords = voctree.quantize(queryRegions.Descriptors());
  std::vector<voctree::Match> matchedImages;
  db.find(requestImageWords, numResults, matchedImages);

  // Match with the N best images
  const float fDistRatio = 0.6;
  typedef flann::L2<unsigned char> MetricT;
  typedef matching::ArrayMatcher_Kdtree_Flann<unsigned char, MetricT> MatcherT;
  POPART_COUT("Build the matcher");
  matching::RegionsMatcherT<MatcherT> matcher(queryRegions);

  // Prepare intrinsics
  POPART_COUT("Prepare query intrinsics");
  const bool bKnownIntrinsic = false;
  Mat3 K = Mat3::Identity();
  //  const Intrinsics::const_iterator iterIntrinsic_I = sfmData.GetIntrinsics().find(view_I->id_intrinsic);
  cameras::Pinhole_Intrinsic * queryIntrinsics = NULL;
  //  if (iterIntrinsic_I == _sfm_data.GetIntrinsics().end())
  //  {
  //    bKnownIntrinsic = false;
  //  }
  //  else
  //  {
  //    intrinsics = dynamic_cast<Pinhole_Intrinsic*>(iterIntrinsic_I->second.get());
  //    if (intrinsics)
  //    {
  //      K = intrinsics->K();
  //    }
  //    else
  //    {
  //      bKnownIntrinsic = false;
  //    }
  //  }

  POPART_COUT("Localization for each image.");
  // For each image retrieved from the voctree
  for(const voctree::Match& matchedImage : matchedImages)
  {
    const IndexT matchedViewIndex = mapDocIdToView[matchedImage.id];
    const std::shared_ptr<sfm::View> matchedView = sfmData.views[matchedViewIndex];
    POPART_COUT("Localize with " << matchedView->s_Img_path);
    const localization::Reconstructed_RegionsT& matchedRegions = localization._regions_per_view[matchedViewIndex];

    // B. Putative Features Matching
    std::vector<matching::IndMatch> vec_featureMatches;
    bool matchWorked = matcher.Match(fDistRatio, matchedRegions._regions, vec_featureMatches);
    if (!matchWorked)
    {
      POPART_COUT("matching with " << matchedView->s_Img_path << " failed! Skipping image");
      continue;
    }
    
    //@fixme let's keep it in a separate block for now
    {
	  // geometric filtering
      Mat featuresI(2, vec_featureMatches.size());
      Mat featuresJ(2, vec_featureMatches.size());

      for(int i = 0; i < vec_featureMatches.size(); ++i)
      {
        const matching::IndMatch& match = vec_featureMatches[i];
        featuresI.col(i) = queryRegions.GetRegionPosition(match._i);
        featuresJ.col(i) = matchedRegions._regions.GetRegionPosition(match._j);
      }

      matching_image_collection::GeometricFilter_FMatrix_AC geometricFilter(4.0);
      std::vector<size_t> vec_matchingInliers;
      bool valid = geometricFilter.Robust_estimation(
                                                     featuresI, // points of the query image
                                                     featuresJ, // points of the matched image
                                                     std::make_pair(imageGray.Width(), imageGray.Height()),
                                                     std::make_pair(imageGray.Width(), imageGray.Height()), // NO! @todo here we need the size of the img in the dataset...
                                                     vec_matchingInliers);

      if(!valid)
      {
        cout << "Unable to robustly matching the query image with the database image " << matchedImage.id;
        continue;
      }
      bool b_guided_matching = true;
      if(!b_guided_matching)
      {
        std::vector<matching::IndMatch> vec_robustFeatureMatches(vec_matchingInliers.size());
        for(const int i : vec_matchingInliers)
        {
          vec_robustFeatureMatches[i] = vec_featureMatches[i];
        }
        // replace the featuresMatches with the robust ones.
        std::swap(vec_featureMatches, vec_robustFeatureMatches);
      }
      else
      {
        // Use the Fundamental Matrix estimated by the robust estimation to
        // perform guided matching.
        // So we ignore the previous matches and recompute all matches.

        geometry_aware::GuidedMatching<
                Mat3,
                openMVG::fundamental::kernel::EpipolarDistanceError>(
                geometricFilter.m_F,
                queryIntrinsics, // cameras::IntrinsicBase of the matched image
                queryRegions, // features::Regions
                sfmData.intrinsics[matchedView->id_intrinsic].get(), // cameras::IntrinsicBase of the query image
                matchedRegions._regions, // features::Regions
                Square(geometricFilter.m_dPrecision_robust),
                Square(fDistRatio),
                vec_featureMatches); // output
      }
    }

    // C. Resection
    Mat34 P;
    {
      // Prepare data for resection
      Mat pt2D(2, vec_featureMatches.size());
      Mat pt3D(3, vec_featureMatches.size());

      // Get the 3D points associated to each matched feature
      std::size_t index = 0;
      for(const matching::IndMatch& featureMatch : vec_featureMatches)
      {
        IndexT trackId3D = matchedRegions._associated3dPoint[featureMatch._j];

        // prepare data for resectioning
        pt3D.col(index) = sfmData.GetLandmarks().at(trackId3D).X;

        const Vec2 feat = queryRegions.GetRegionPosition(featureMatch._i);
        if(bKnownIntrinsic)
          pt2D.col(index) = queryIntrinsics->get_ud_pixel(feat);
        else
          pt2D.col(index) = feat;

        ++index;
      }

      // Do the resectioning: compute the camera pose.
      std::vector<size_t> vec_inliers;
      double errorMax = std::numeric_limits<double>::max();

      bool bResection = sfm::robustResection(
                                             std::make_pair(imageGray.Width(), imageGray.Height()),
                                             pt2D, pt3D,
                                             &vec_inliers,
                                             // Use intrinsic guess if possible
                                             (bKnownIntrinsic) ? &K : NULL,
                                             &P, &errorMax);

      std::cout << std::endl
              << "-------------------------------" << std::endl
              << "-- Robust Resection using view: " << mapDocIdToView[matchedImage.id] << std::endl
              << "-- Resection status: " << bResection << std::endl
              << "-- #Points used for Resection: " << vec_featureMatches.size() << std::endl
              << "-- #Points validated by robust Resection: " << vec_inliers.size() << std::endl
              << "-- Threshold: " << errorMax << std::endl
              << "-------------------------------" << std::endl;

      if(!bResection)
      {
        std::cout << "Resection FAILED" << std::endl;
        continue;
      }
    }
    std::cout << "Resection SUCCEDED" << std::endl;
    // Decompose P matrix
    Mat3 K_, R_;
    Vec3 t_;
    KRt_From_P(P, &K_, &R_, &t_);

    std::cout << "K: " << K_ << std::endl;

    {
      sfm::SfM_Data exportedScene(sfmData);

      const IndexT newViewID = sfmData.GetViews().size();
      std::shared_ptr<sfm::View> newView(new sfm::View(mediaFilepath + "_QUERY.JPG",
                                                       newViewID, // view_id
                                                       exportedScene.GetIntrinsics().size(), // intrinsic_id
                                                       exportedScene.GetPoses().size(), // pose_id
                                                       imageGray.Width(), // width
                                                       imageGray.Height())); // height

      exportedScene.views[newViewID] = newView;
      POPART_COUT("NB VIEWS TO EXPORT: " << exportedScene.views.size());
      exportedScene.poses[newView->id_pose] = geometry::Pose3(R_, -R_.transpose() * t_);
      exportedScene.intrinsics[newView->id_intrinsic] = std::make_shared<cameras::Pinhole_Intrinsic>(
              cameras::Pinhole_Intrinsic(
                                         imageGray.Width(),
                                         imageGray.Height(),
                                         K_));

      std::string exportFilepathBin = bfs::path(exportFilepath).replace_extension(".bin").string();

      sfm::Save(exportedScene, exportFilepath, sfm::ALL);
      sfm::Save(exportedScene, exportFilepathBin, sfm::ALL);

      sfm::SfM_Data exportTrack;
      exportTrack.views[newViewID] = newView;
      exportTrack.poses[newView->id_pose] = exportedScene.poses[newView->id_pose];
      exportTrack.intrinsics[newView->id_intrinsic] = exportedScene.intrinsics[newView->id_intrinsic];

      sfm::Save(exportTrack, bfs::path(exportFilepath).replace_extension(".track_only" + bfs::path(exportFilepath).extension().string()).string(), sfm::ALL);
      exportTrack.structure = sfmData.structure;

      sfm::Save(exportTrack, bfs::path(exportFilepath).replace_extension(".track" + bfs::path(exportFilepath).extension().string()).string(), sfm::ALL);
      sfm::Save(exportTrack, bfs::path(exportFilepathBin).replace_extension(".track" + bfs::path(exportFilepathBin).extension().string()).string(), sfm::ALL);

      POPART_COUT("Export: " << exportFilepath);
    }

    // @todo: refine pose with bundle
  }

  return EXIT_SUCCESS;
}
